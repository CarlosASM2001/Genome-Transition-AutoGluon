{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 - Inference Smoke Test\n",
        "\n",
        "Este notebook valida que los modelos campeones (EI, IE, ZE, EZ) cargan correctamente desde `training/reports/model_registry.json` y pueden inferir sobre muestras reales.\n",
        "\n",
        "Checks principales:\n",
        "- Carga de `TabularPredictor` por transicion.\n",
        "- `predict` devuelve el mismo numero de filas que la entrada.\n",
        "- `predict_proba` devuelve probabilidades validas en `[0, 1]`.\n",
        "- Exporta un reporte consolidado a `training/reports/inference_smoke_test.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "SAMPLE_SIZE = 300\n",
        "\n",
        "\n",
        "def find_project_root():\n",
        "    cwd = Path.cwd().resolve()\n",
        "    for candidate in [cwd, *cwd.parents]:\n",
        "        if (candidate / \"training\").exists() and (candidate / \"data\").exists():\n",
        "            return candidate\n",
        "    raise FileNotFoundError(\"Could not detect project root containing training/ and data/\")\n",
        "\n",
        "\n",
        "project_root = find_project_root()\n",
        "registry_path = project_root / \"training/reports/model_registry.json\"\n",
        "report_path = project_root / \"training/reports/inference_smoke_test.csv\"\n",
        "\n",
        "data_path_map = {\n",
        "    \"EI\": \"data/data_ei.csv\",\n",
        "    \"IE\": \"data/data_ie.csv\",\n",
        "    \"ZE\": \"data/data_ze.csv\",\n",
        "    \"EZ\": \"data/data_ez.csv\",\n",
        "}\n",
        "\n",
        "project_root, registry_path, report_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not registry_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Registry not found at {registry_path}. Run training/src/model_selection.py first.\"\n",
        "    )\n",
        "\n",
        "with registry_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    registry = json.load(f)\n",
        "\n",
        "models_cfg = registry.get(\"models\", {})\n",
        "if not models_cfg:\n",
        "    raise ValueError(\"Registry has no models configured under 'models'.\")\n",
        "\n",
        "expected = {\"EI\", \"IE\", \"ZE\", \"EZ\"}\n",
        "missing = expected - set(models_cfg.keys())\n",
        "if missing:\n",
        "    print(f\"Warning: missing transitions in registry: {sorted(missing)}\")\n",
        "\n",
        "registry_df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"transition\": transition,\n",
        "            \"model_path\": cfg.get(\"path\"),\n",
        "            \"registry_f1\": cfg.get(\"f1\"),\n",
        "        }\n",
        "        for transition, cfg in sorted(models_cfg.items())\n",
        "    ]\n",
        ")\n",
        "registry_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_binary(values):\n",
        "    s = pd.Series(values).copy()\n",
        "    mapped = s.astype(str).str.strip().str.lower().map(\n",
        "        {\n",
        "            \"1\": 1,\n",
        "            \"0\": 0,\n",
        "            \"true\": 1,\n",
        "            \"false\": 0,\n",
        "            \"yes\": 1,\n",
        "            \"no\": 0,\n",
        "        }\n",
        "    )\n",
        "    if mapped.isna().any():\n",
        "        numeric = pd.to_numeric(s, errors=\"coerce\")\n",
        "        if numeric.notna().all():\n",
        "            mapped = numeric.astype(int)\n",
        "    if mapped.isna().any():\n",
        "        raise ValueError(\"Could not normalize binary values to 0/1\")\n",
        "    return mapped.astype(int).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def get_positive_proba(proba_output):\n",
        "    if isinstance(proba_output, pd.Series):\n",
        "        return pd.to_numeric(proba_output, errors=\"coerce\").astype(float).reset_index(drop=True)\n",
        "\n",
        "    if isinstance(proba_output, pd.DataFrame):\n",
        "        for col in [1, \"1\", True, \"True\", \"true\", \"positive\", \"pos\", \"label_1\"]:\n",
        "            if col in proba_output.columns:\n",
        "                return pd.to_numeric(proba_output[col], errors=\"coerce\").astype(float).reset_index(drop=True)\n",
        "\n",
        "        if proba_output.shape[1] == 2:\n",
        "            return pd.to_numeric(proba_output.iloc[:, 1], errors=\"coerce\").astype(float).reset_index(drop=True)\n",
        "\n",
        "        return pd.to_numeric(proba_output.max(axis=1), errors=\"coerce\").astype(float).reset_index(drop=True)\n",
        "\n",
        "    raise TypeError(f\"Unsupported probability output type: {type(proba_output)}\")\n",
        "\n",
        "\n",
        "def sample_transition_dataframe(transition, sample_size=SAMPLE_SIZE, random_state=RANDOM_STATE):\n",
        "    csv_path = project_root / data_path_map[transition]\n",
        "    if not csv_path.exists():\n",
        "        raise FileNotFoundError(f\"CSV for {transition} not found at {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    feature_cols = [c for c in df.columns if c.startswith(\"B\")]\n",
        "    if not feature_cols:\n",
        "        raise ValueError(f\"No feature columns (B*) found in {csv_path}\")\n",
        "\n",
        "    X = df[feature_cols].copy()\n",
        "    y = normalize_binary(df[\"label\"])\n",
        "\n",
        "    if len(X) > sample_size:\n",
        "        sample_idx = X.sample(n=sample_size, random_state=random_state).index\n",
        "        X = X.loc[sample_idx].reset_index(drop=True)\n",
        "        y = y.loc[sample_idx].reset_index(drop=True)\n",
        "    else:\n",
        "        X = X.reset_index(drop=True)\n",
        "        y = y.reset_index(drop=True)\n",
        "\n",
        "    return X, y, csv_path\n",
        "\n",
        "\n",
        "def compute_binary_metrics(y_true, y_pred):\n",
        "    y_true = normalize_binary(y_true)\n",
        "    y_pred = normalize_binary(y_pred)\n",
        "\n",
        "    tp = int(((y_pred == 1) & (y_true == 1)).sum())\n",
        "    tn = int(((y_pred == 0) & (y_true == 0)).sum())\n",
        "    fp = int(((y_pred == 1) & (y_true == 0)).sum())\n",
        "    fn = int(((y_pred == 0) & (y_true == 1)).sum())\n",
        "\n",
        "    accuracy = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "    precision = tp / max(tp + fp, 1)\n",
        "    recall = tp / max(tp + fn, 1)\n",
        "    f1 = (2 * precision * recall) / max(precision + recall, 1e-12)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"precision\": float(precision),\n",
        "        \"recall\": float(recall),\n",
        "        \"f1\": float(f1),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "\n",
        "for transition, cfg in sorted(models_cfg.items()):\n",
        "    row = {\n",
        "        \"transition\": transition,\n",
        "        \"status\": \"FAIL\",\n",
        "        \"model_path\": \"\",\n",
        "        \"data_csv\": \"\",\n",
        "        \"n_rows\": 0,\n",
        "        \"predict_ok\": False,\n",
        "        \"proba_ok\": False,\n",
        "        \"pred_classes\": \"\",\n",
        "        \"proba_min\": None,\n",
        "        \"proba_max\": None,\n",
        "        \"proba_mean\": None,\n",
        "        \"accuracy\": None,\n",
        "        \"precision\": None,\n",
        "        \"recall\": None,\n",
        "        \"f1_smoke\": None,\n",
        "        \"registry_f1\": cfg.get(\"f1\"),\n",
        "        \"error\": \"\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        if transition not in data_path_map:\n",
        "            raise KeyError(f\"No CSV mapping configured for transition '{transition}'\")\n",
        "\n",
        "        model_path_raw = cfg.get(\"path\")\n",
        "        if not model_path_raw:\n",
        "            raise ValueError(f\"Model path missing for transition '{transition}'\")\n",
        "\n",
        "        model_path = Path(model_path_raw)\n",
        "        if not model_path.is_absolute():\n",
        "            model_path = project_root / model_path\n",
        "\n",
        "        predictor = TabularPredictor.load(str(model_path))\n",
        "        X, y_true, csv_path = sample_transition_dataframe(transition)\n",
        "\n",
        "        preds_raw = predictor.predict(X, as_pandas=True)\n",
        "        y_pred = normalize_binary(preds_raw)\n",
        "\n",
        "        proba_raw = predictor.predict_proba(X, as_pandas=True)\n",
        "        y_score = get_positive_proba(proba_raw)\n",
        "\n",
        "        predict_ok = len(y_pred) == len(X)\n",
        "        proba_ok = bool(y_score.notna().all() and ((y_score >= 0) & (y_score <= 1)).all())\n",
        "\n",
        "        metrics = compute_binary_metrics(y_true, y_pred)\n",
        "\n",
        "        row.update(\n",
        "            {\n",
        "                \"status\": \"PASS\" if (predict_ok and proba_ok) else \"FAIL\",\n",
        "                \"model_path\": str(model_path),\n",
        "                \"data_csv\": str(csv_path),\n",
        "                \"n_rows\": int(len(X)),\n",
        "                \"predict_ok\": bool(predict_ok),\n",
        "                \"proba_ok\": bool(proba_ok),\n",
        "                \"pred_classes\": \",\".join(map(str, sorted(y_pred.unique().tolist()))),\n",
        "                \"proba_min\": float(y_score.min()),\n",
        "                \"proba_max\": float(y_score.max()),\n",
        "                \"proba_mean\": float(y_score.mean()),\n",
        "                \"accuracy\": metrics[\"accuracy\"],\n",
        "                \"precision\": metrics[\"precision\"],\n",
        "                \"recall\": metrics[\"recall\"],\n",
        "                \"f1_smoke\": metrics[\"f1\"],\n",
        "                \"error\": \"\",\n",
        "            }\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        row[\"error\"] = repr(exc)\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(rows).sort_values(\"transition\").reset_index(drop=True)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "results_df.to_csv(report_path, index=False)\n",
        "print(f\"Smoke test report saved to: {report_path}\")\n",
        "\n",
        "summary_cols = [\n",
        "    \"transition\",\n",
        "    \"status\",\n",
        "    \"n_rows\",\n",
        "    \"predict_ok\",\n",
        "    \"proba_ok\",\n",
        "    \"accuracy\",\n",
        "    \"f1_smoke\",\n",
        "    \"registry_f1\",\n",
        "    \"error\",\n",
        "]\n",
        "results_df[summary_cols]\n",
        "\n",
        "if (results_df[\"status\"] != \"PASS\").any():\n",
        "    failed = results_df.loc[results_df[\"status\"] != \"PASS\", \"transition\"].tolist()\n",
        "    raise RuntimeError(f\"Smoke test failed for transitions: {failed}\")\n",
        "\n",
        "print(\"Smoke test completed successfully for all transitions.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
