{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Entrenar modelo con AutoGluon\n",
        "\n",
        "Este notebook entrena un clasificador tabular para predecir la clase de transicion (`EI`, `IE`, `ZE`, `EZ`) usando `transition_dataset.csv`."
      ],
      "id": "0dc5bb8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f1738176"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_project_root(start: Path) -> Path:\n",
        "    current = start.resolve()\n",
        "    for candidate in [current, *current.parents]:\n",
        "        if (candidate / \"data\").exists() and (candidate / \"modeling\").exists():\n",
        "            return candidate\n",
        "    raise FileNotFoundError(\"No se encontro la raiz del proyecto.\")\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "DATASET_PATH = PROJECT_ROOT / \"modeling\" / \"data\" / \"processed\" / \"transition_dataset.csv\"\n",
        "MODEL_DIR = PROJECT_ROOT / \"modeling\" / \"artifacts\" / \"autogluon_model\"\n",
        "REPORT_DIR = PROJECT_ROOT / \"modeling\" / \"outputs\"\n",
        "\n",
        "LABEL_COLUMN = \"transition_label\"\n",
        "DROP_COLUMNS = [\"gene_id\", \"chromosome\", \"global_position\", \"local_position\"]\n",
        "TIME_LIMIT = 900\n",
        "PRESETS = \"medium_quality\"\n",
        "EVAL_METRIC = \"accuracy\"\n",
        "TEST_SIZE = 0.2\n",
        "SEED = 42\n",
        "\n",
        "DATASET_PATH"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2a16bf24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def split_train_test(df: pd.DataFrame, label_column: str, test_size: float, seed: int):\n",
        "    label_counts = df[label_column].value_counts(dropna=False)\n",
        "\n",
        "    if test_size <= 0:\n",
        "        return df.sample(frac=1, random_state=seed).reset_index(drop=True), None\n",
        "\n",
        "    if label_counts.min() < 2:\n",
        "        return df.sample(frac=1, random_state=seed).reset_index(drop=True), None\n",
        "\n",
        "    train_parts = []\n",
        "    test_parts = []\n",
        "\n",
        "    for _, group in df.groupby(label_column):\n",
        "        shuffled = group.sample(frac=1, random_state=seed)\n",
        "        test_count = int(round(len(shuffled) * test_size))\n",
        "        test_count = max(1, test_count)\n",
        "        if test_count >= len(shuffled):\n",
        "            test_count = len(shuffled) - 1\n",
        "\n",
        "        test_parts.append(shuffled.iloc[:test_count])\n",
        "        train_parts.append(shuffled.iloc[test_count:])\n",
        "\n",
        "    train_df = pd.concat(train_parts, ignore_index=True).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    test_df = pd.concat(test_parts, ignore_index=True).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def json_safe(value):\n",
        "    if isinstance(value, dict):\n",
        "        return {k: json_safe(v) for k, v in value.items()}\n",
        "    if isinstance(value, list):\n",
        "        return [json_safe(v) for v in value]\n",
        "    if hasattr(value, \"item\"):\n",
        "        try:\n",
        "            return value.item()\n",
        "        except Exception:\n",
        "            return str(value)\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7740b964"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = pd.read_csv(DATASET_PATH, low_memory=False)\n",
        "if dataset.empty:\n",
        "    raise ValueError(f\"Dataset vacio: {DATASET_PATH}\")\n",
        "\n",
        "if LABEL_COLUMN not in dataset.columns:\n",
        "    raise ValueError(f\"No existe la columna objetivo '{LABEL_COLUMN}'\")\n",
        "\n",
        "columns_to_drop = [c for c in DROP_COLUMNS if c in dataset.columns and c != LABEL_COLUMN]\n",
        "modeling_df = dataset.drop(columns=columns_to_drop, errors=\"ignore\")\n",
        "\n",
        "feature_columns = [c for c in modeling_df.columns if c != LABEL_COLUMN]\n",
        "if not feature_columns:\n",
        "    raise ValueError(\"No quedan columnas de entrada para entrenar.\")\n",
        "if modeling_df[LABEL_COLUMN].nunique(dropna=False) < 2:\n",
        "    raise ValueError(\"Se requieren al menos 2 clases para entrenar.\")\n",
        "\n",
        "train_df, test_df = split_train_test(modeling_df, LABEL_COLUMN, TEST_SIZE, SEED)\n",
        "\n",
        "print(\"Train rows:\", len(train_df))\n",
        "print(\"Test rows:\", 0 if test_df is None else len(test_df))\n",
        "print(modeling_df[LABEL_COLUMN].value_counts(dropna=False).to_string())"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d1fb610d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=LABEL_COLUMN,\n",
        "    path=str(MODEL_DIR),\n",
        "    eval_metric=EVAL_METRIC,\n",
        ")\n",
        "\n",
        "predictor.fit(\n",
        "    train_data=train_df,\n",
        "    presets=PRESETS,\n",
        "    time_limit=TIME_LIMIT,\n",
        ")\n",
        "\n",
        "if test_df is not None and not test_df.empty:\n",
        "    metrics = predictor.evaluate(test_df, silent=True)\n",
        "    leaderboard = predictor.leaderboard(test_df, silent=True)\n",
        "    evaluated_on = \"test\"\n",
        "    evaluated_rows = len(test_df)\n",
        "else:\n",
        "    metrics = predictor.evaluate(train_df, silent=True)\n",
        "    leaderboard = predictor.leaderboard(silent=True)\n",
        "    evaluated_on = \"train\"\n",
        "    evaluated_rows = len(train_df)\n",
        "\n",
        "leaderboard_path = REPORT_DIR / \"leaderboard.csv\"\n",
        "metrics_path = REPORT_DIR / \"metrics.json\"\n",
        "\n",
        "leaderboard.to_csv(leaderboard_path, index=False)\n",
        "\n",
        "metrics_payload = {\n",
        "    \"dataset_path\": str(DATASET_PATH),\n",
        "    \"label_column\": LABEL_COLUMN,\n",
        "    \"dropped_columns\": columns_to_drop,\n",
        "    \"train_rows\": len(train_df),\n",
        "    \"test_rows\": 0 if test_df is None else len(test_df),\n",
        "    \"evaluated_on\": evaluated_on,\n",
        "    \"evaluated_rows\": evaluated_rows,\n",
        "    \"eval_metric\": EVAL_METRIC,\n",
        "    \"metrics\": json_safe(metrics),\n",
        "}\n",
        "\n",
        "with metrics_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics_payload, f, indent=2, ensure_ascii=True)\n",
        "\n",
        "print(f\"Modelo guardado en: {MODEL_DIR}\")\n",
        "print(f\"Leaderboard: {leaderboard_path}\")\n",
        "print(f\"Metricas: {metrics_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8f3391e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "leaderboard.head(20)"
      ],
      "id": "1e95fbf2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}